# LangGraph Retrieval Agent Template

[![CI](https://github.com/langchain-ai/retrieval-agent-template/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/langchain-ai/retrieval-agent-template/actions/workflows/unit-tests.yml)
[![Integration Tests](https://github.com/langchain-ai/retrieval-agent-template/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/langchain-ai/retrieval-agent-template/actions/workflows/integration-tests.yml)

This LangGraph template implements a simple, extensible agent that answers questions based on a retriever.

![Graph view in LangGraph studio UI](./static/studio_ui.png)

## Project Prerequisites

Assuming you have already [installed LangGraph Studio](https://github.com/langchain-ai/langgraph-studio?tab=readme-ov-file#download).

By default, this template uses:

- OpenAI `text-embedding-3-small` model for embedding documents. Requires an OpenAI API key to be configured.
- Anthropic `claude-3-5-sonnet` for generating responses. Requires an Anthropic API key to be configured.
- Elasticsearch for retrieval and indexing on vectorised documents.

All that's left is to index documents into Elasticsearch through the indexer graph (or your selected search provider).

Copy the [.env.example](.env.example) file. We will copy the relevant environment variables there:

```bash
cp .env.example .env
```

1. Setup pre-requisites.

<details>
<summary>Setup for retrieval provider</summary>

The `retriever_provider` configuration defaults to `elastic`. Follow the instructions below get set up, or pick one of the additional options.

### Setup Elasticsearch

You can setup a local Elasticsearch instance or use Elastic Cloud.

#### On Elastic Cloud

1. Signup for a free trial with [Elastic Cloud](https://cloud.elastic.co/registration?onboarding_token=search&cta=cloud-registration&tech=trial&plcmt=article%20content&pg=langchain).
2. Get the Elasticsearch URL, found under Applications of your deployment.
3. Create an API key. See the [official elastic documentation](https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key) for more information.
4. Copy the URL and API key to your `.env` file created above:

```
ELASTICSEARCH_URL=<ES_URL>
ELASTICSEARCH_API_KEY=<API_KEY>
```

#### Locally with Docker

```
docker run -p 127.0.0.1:9200:9200 -d --name elasticsearch --network elastic-net \
  -e ELASTIC_PASSWORD=changeme \
  -e "discovery.type=single-node" \
  -e "xpack.security.http.ssl.enabled=false" \
  -e "xpack.license.self_generated.type=trial" \
  docker.elastic.co/elasticsearch/elasticsearch:8.15.1
```

See the [official Elastic documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/run-elasticsearch-locally.html) for more information on running it locally.

Then use the `.env.example` to create an `.env` file with the following:

```
# As both Elasticsearch and LangGraph Studio runs in Docker, we need to use host.docker.internal to access.
ELASTICSEARCH_URL=http://host.docker.internal:9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=changeme
```

Once you've set this up, you can open this template in LangGraph studio.

</details>

<details>
<summary>Setup for embedding model</summary>

The `embedding_model` configurable field defaults to `text-embedding-3-small`.

... TODO: Add

</details>

## Graphs

This template contains two graphs, each in separate files.

1. [index](./retrieval_graph/index_graph.py)

This "graph" is merely a single endpoint that lets a user post content to be indexed.

All documents are stored with the user's user_id (provided via configuration) as metadata so it can be filtered per-user.

2. [retrieval_graph](./retrieval_graph/graph.py)

This is a simple pipe for conducting conversational RAG. It has 3 primary steps as nodes.

1. Generate query: either take the user's input (if first step) or call an LLM to generate the query based on the conversation.
2. Retrieve docs: this uses the retriever [stored in context](https://langchain-ai.github.io/langgraph/how-tos/state-context-key/) to fetch docs, filtered by the user_id.
3. Generate response: call an LLM with the conversation + formatted doc results.

## Repo Structure

```txt
.
├── LICENSE
├── Makefile
├── README.md
├── langgraph.json
├── pyproject.toml
├── src
│   └── retrieval_graph
│       ├── __init__.py
│       ├── __pycache__
│       ├── configuration.py
│       ├── graph.py
│       ├── index_graph.py
│       ├── retrieval.py
│       ├── state.py
│       └── utils.py
└── tests
    ├── integration_tests
    │   └── __init__.py
    └── unit_tests
        └── __init__.py
```

<!--
Configuration auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
{
  "config_schemas": {
    "indexer": {
      "type": "object",
      "properties": {
        "user_id": {
          "type": "string"
        },
        "embedding_model": {
          "type": "string",
          "default": "openai/text-embedding-3-small",
          "environment": [
            {
              "value": "cohere/embed-english-light-v2.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-english-light-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-english-v2.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-english-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-multilingual-light-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-multilingual-v2.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-multilingual-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "openai/text-embedding-3-large",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/text-embedding-3-small",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/text-embedding-ada-002",
              "variables": "OPENAI_API_KEY"
            }
          ]
        },
        "retriever_provider": {
          "enum": [
            "elastic",
            "elastic-local",
            "mongodb",
            "pinecone"
          ],
          "default": "elastic",
          "environment": [
            {
              "value": "elastic",
              "variables": [
                "ELASTICSEARCH_URL",
                "ELASTICSEARCH_API_KEY"
              ]
            },
            {
              "value": "elastic-local",
              "variables": [
                "ELASTICSEARCH_URL",
                "ELASTICSEARCH_USER",
                "ELASTICSEARCH_PASSWORD"
              ]
            },
            {
              "value": "mongodb",
              "variables": [
                "MONGODB_URI"
              ]
            },
            {
              "value": "pinecone",
              "variables": [
                "PINECONE_API_KEY",
                "PINECONE_INDEX_NAME"
              ]
            }
          ]
        },
        "search_kwargs": {
          "type": "object"
        }
      }
    },
    "retrieval_graph": {
      "type": "object",
      "properties": {
        "user_id": {
          "type": "string"
        },
        "thread_id": {
          "type": "string"
        },
        "embedding_model": {
          "type": "string",
          "default": "openai/text-embedding-3-small",
          "environment": [
            {
              "value": "cohere/embed-english-light-v2.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-english-light-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-english-v2.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-english-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-multilingual-light-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-multilingual-v2.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "cohere/embed-multilingual-v3.0",
              "variables": "COHERE_API_KEY"
            },
            {
              "value": "openai/text-embedding-3-large",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/text-embedding-3-small",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/text-embedding-ada-002",
              "variables": "OPENAI_API_KEY"
            }
          ]
        },
        "retriever_provider": {
          "enum": [
            "elastic",
            "elastic-local",
            "mongodb",
            "pinecone"
          ],
          "default": "elastic",
          "environment": [
            {
              "value": "elastic",
              "variables": [
                "ELASTICSEARCH_URL",
                "ELASTICSEARCH_API_KEY"
              ]
            },
            {
              "value": "elastic-local",
              "variables": [
                "ELASTICSEARCH_URL",
                "ELASTICSEARCH_USER",
                "ELASTICSEARCH_PASSWORD"
              ]
            },
            {
              "value": "mongodb",
              "variables": [
                "MONGODB_URI"
              ]
            },
            {
              "value": "pinecone",
              "variables": [
                "PINECONE_API_KEY",
                "PINECONE_INDEX_NAME"
              ]
            }
          ]
        },
        "search_kwargs": {
          "type": "object"
        },
        "response_system_prompt": {
          "type": "string",
          "default": "You are a helpful AI assistant. Answer the user's questions based on the retrieved documents.\n\n{retrieved_docs}\"\n\nSystem time: {system_time}"
        },
        "response_model": {
          "type": "string",
          "default": "anthropic/claude-3-5-sonnet-20240620",
          "environment": [
            {
              "value": "anthropic/claude-1.2",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-2.0",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-2.1",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-5-sonnet-20240620",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-haiku-20240307",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-opus-20240229",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-sonnet-20240229",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-instant-1.2",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "fireworks/gemma2-9b-it",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-70b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-70b-instruct-hf",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-8b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-8b-instruct-hf",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-405b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-405b-instruct-long",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-70b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-8b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mixtral-8x22b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mixtral-8x7b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mixtral-8x7b-instruct-hf",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mythomax-l2-13b",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/phi-3-vision-128k-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/phi-3p5-vision-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/starcoder-16b",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/yi-large",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0125",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0301",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-1106",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-16k",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-16k-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0125-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0314",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-1106-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k-0314",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-turbo",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-turbo-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-vision-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4o",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4o-mini",
              "variables": "OPENAI_API_KEY"
            }
          ]
        },
        "query_system_prompt": {
          "type": "string",
          "default": "Generate search queries to retrieve documents that may help answer the user's question. Previously, you made the following queries:\n    \n<previous_queries/>\n{queries}\n</previous_queries>\n\nSystem time: {system_time}"
        },
        "query_model": {
          "type": "string",
          "default": "openai/gpt-4o-mini",
          "environment": [
            {
              "value": "anthropic/claude-1.2",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-2.0",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-2.1",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-5-sonnet-20240620",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-haiku-20240307",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-opus-20240229",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-sonnet-20240229",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-instant-1.2",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "fireworks/gemma2-9b-it",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-70b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-70b-instruct-hf",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-8b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3-8b-instruct-hf",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-405b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-405b-instruct-long",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-70b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/llama-v3p1-8b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mixtral-8x22b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mixtral-8x7b-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mixtral-8x7b-instruct-hf",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/mythomax-l2-13b",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/phi-3-vision-128k-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/phi-3p5-vision-instruct",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/starcoder-16b",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "fireworks/yi-large",
              "variables": "FIREWORKS_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0125",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0301",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-1106",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-16k",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-16k-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0125-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0314",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-1106-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k-0314",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-turbo",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-turbo-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-vision-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4o",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4o-mini",
              "variables": "OPENAI_API_KEY"
            }
          ]
        }
      }
    }
  }
}
-->
